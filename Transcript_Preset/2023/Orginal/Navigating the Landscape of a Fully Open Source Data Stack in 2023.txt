 Hello everyone, welcome to the third day and last day of this amazing conference. Thank you all for keeping here with us. And we have here, sorry, sorry, we have here a vaccine, though, to me, who is founder of preset and you already met him since the first day of the conference. He's also one of the benefit organizers. So I don't want to take more time from do max. There you go. All right, well, thank you, Mara and good morning or good day everybody, depending on where you're at. I want to say what I'm speaking from here today. It is 8 a.m. so I tried to wake up a little bit earlier, kind of get my brain going, had a coffee or two. And yeah, ready to go and kick things up. Hopefully there won't be too many distractions in the back of the kids are getting ready for school and all this good stuff. So hopefully, you know, I don't get too much background noise here. But it gets thing, let's get things started. So today, I've got a really ambitious topic, which is talking about navigating the landscape of a fully open source data stack. Of course, I'm not necessarily a open source maximalist in the sense of like, are you going to run your full site? You've got to be open source. But it's more of a thought of exercise of looking at the different pieces of this stack, like trying to delaminate the stack, look at some of the important layers. And looking at some of the open source solutions that exist across the stack and talking about how they compare to some of the vendor, the top vendor solutions in the space. Already did a pretty good intro on me, but I always squeeze in the slides so people know a little bit about me before I get started. So, you know, probably the first thing to say about me, especially in this context, the context of this conference is, I love building data tools. That's what I've been doing over the past decade or so, started a lot of open source projects, a lot that didn't get popular, but I also started Apache Airflow and 14. Apache SuperSet, these two got pretty popular. And they will get mentioned as I get into their respective layer of the stack as I unpack and look at, you know, the different layer of the stacks and the tools that exist. Before recently, I started a company called Preset, so we do essentially manage hosted SuperSet as a service and there you can get the latest, greatest SuperSet. If you're not familiar with SuperSet, the best way to check it out is to try to frame your own product on preset. We got a good sense of it. So, I encourage people to go and do that. All right, let's get things started. So as I said, just a moment ago, I want to make sure my slides are working good. Yes. All right, so what I want to do today as decal pose the modern data stack are the typical data stack and unpack it into some of its key components. And for each layer, review some of the open source solutions that exist and how they compare to some of the commercial vendors in the space. Of course, this is a super ambitious talk. Like there's a lot of layers in the stack. There's a lot of products. These products are changing extremely fast. So I want to put this disclaimer together saying this as much as I did some research, as much as I bait all year round in open source and data and talk to a lot of people about their stack. I don't know everything and it's really hard to keep up with everything. So I apologize and offensive. There's some missing logos. If I miscalculate their eyes, anything, but the idea is really to give you some set of pointer to get an idea of the landscape. And of course, you should do your own research and look at some of the up and comers that maybe I have not mentioned. So one more thought on this is the fact that part of reason why I got involved with OSA Khan is because I wanted in many ways for this information about everything that exists, the new tools that are popping up, what's happening in the open source project we know about. It's very much a scope of OSA Khan to do this. So I've been watching some of the talks. It would have been a lot easier for me to come up with this talk after watching all the talks from OSA Khan. So if you want to know more about any of the solutions or the things I'm going to talk about, there's going to, there's a lot of resources online. OSA Khan is a resource here too. All right. So in terms of the approach, how are we going to delaminate this stack? So I feel like the folks at Endrees and Arwitz came up with a blog post, maybe a little bit more than a year ago called Unified Data Infrastructure. They have, they went through some iteration of it. And I believe they did a really good job at mapping the different layers and the left end boxes and I did find some of the key players in this space. So we're going to follow this model in some capacity. But this is too ambitious for a third-evented talk. So I decided to focus on a subset here, so highlighting an orange from the things that pertains more directly to modern business intelligence, which conveniently is a little bit more my area of expertise. And it's a reduced scope so I don't have to talk to cover absolutely everything. I believe Nick Shrek and his stocky yesterday also used the same image that I'm showing here, which highlights the nonsense of just how much I call it nonsense. But we're lucky to have so much diversity in the data space and so many vendors, so many solutions at the same time, you know, being on the top or a little bit past the top of the hype cycle around data and open source. And that creates a lot of confusion, right? There's so many logos and tools and solutions that exist, that it's really hard to make sense of all of this. So like very much I got the end of the stock, like you should fully be able to make sense of everything here. And I'm just kidding. So here, you know, we're going to try to navigate some of the part here and highlight some of the logos I'm familiar with. So we won't be able to cover everything, of course, and we won't be able to sort everything through everything, but at least we'll get an overview of what's happening and what's interesting and some of the things you should know about. So getting a little bit more of this scope for this stock, so we'll talk about some of what I call the vital components. If you're small startup or you know, you start with it from scratch, you know, a data team from zero, like you're going to need a data warehouse or some sort of like data like data warehouse, you're going to need a data replication. You're going to need a solution for doing data transformation as well as a some sort of business intelligence data visualization dashboarding solution. So those are the primary things I'm going to try to talk about today. And then I'll get into some of the things that as you grow your data team, so you probably need data catalog data, you know, data workspace or notebook solutions. So I'll touch on these. And then there's a lot of things that I won't cover because there's just not enough time and attention over the next half hour. And also there's, you know, there's, there's, there's not necessarily like my area of expertise. So I won't get into this streaming and the, you know, data observability, for instance. All right. Let's get started with the very first layer of the stack, which is probably more than a layer. It's probably a composite layer that's extremely complex. But I want to talk about this area that is the data warehouse, lake house, database, like, you know, your query engine. So you're going to need something here to process your data, query your data and probably transform your data as often done on that layer as well. So first two things to highlight is open source has been very, very active in this area of the stack. It's a very dynamic place with open source. And really over the past decade, open source was very much dominating a lot of what's happening here over the past, maybe I would say five years or so. Snowflake and BigQuery. I've, I've gained a lot of, of market share. And I think that's just for the sheer convenience. The fact that they're so easy to get started with. They're very much pay as you go. So if you have little data, it's very, very convenient to start with. You know, if like BigQuery, you start quick. It's cheap until it's not, but it's very much pay as you go. There's no minimum price to get in. So the solution have been extremely popular. On the open source side of the house, there's a lot of solution. There's also a lot of commercial open source vendors. So a lot of options here, maybe leading the pack in terms of some of the solution in terms of adoption. And on much they solve, the space is, you know, Trino Presto, Spark SQL, Dremio as like the your Lakehouse query engine. We still have this very, very dynamic space around Olapso. Here, you know, the in-memory real-time distributed databases, like, you know, Trino, Lakehouse, Pino, have been extremely dynamic and it's been a fairly competitive space too. With great hosted solution, right? The commercial open source vendor to our very, very active here. So here, a lot to enjoy and very convenient. And then not so surprisingly, but a lot of people, at least like in my experience, talking to folks, even looking at analytics of how people are using SuperSem preset, we see a lot of Postgres. So Postgres is pretty decent database when it comes to running some analytical workload. And not everyone needs an affiliate database that scales the infinity. So there's a lot of headroom even starting with your Postgres or my SQL type solution. So I wanted to point out that Postgres got a pretty good like column in our store engine behind the scene. So a lot you can do here. I think that's an area, you know, that's a big kind of commitment when you make decision on that layer of the data stack. And there is a lot of solution and things to look into. And it's not impossible to mix and match, right? So maybe you need a Lake Engine and an Olap Engine. That's also an option here. Next one. So I'm going to talk about data replication. So the EL and ELT, so for people not so familiar with that sort of ETL historically has been like extraction, transforming load. So it's really about data transformation. What's more fashionable these days is to do ELT, which is the idea of like extracting load your data and then do the transformation and inside your data warehouse or data lake. So that EL and ELT now is a very dynamic portion. It does appear that five trenches with the convenience as a commercial vendor has been leading the pack in many ways. One thing I wanted to say about this space is like, don't do it yourself, right? So maybe historically people would write their own little script that would call the APIs of the different solution and trying to sync the data with. Nowadays, I think it makes a lot of sense to use a product that can do that for you. Just to be clear, the problem we're trying to solve here is the normal company or your average company's got a lot of SaaS products, a lot of data that lives inside your CRM and your applicant tracking system. So you end up with a lot of data that's just scattered across SaaS tool and then you want to bring all of that into the data warehouse. And really this space is a space where you should not build on your own and you should really use one of the tools. Luckily, there's a lot of tools. This feels like an area where open source should dominate, because there is a very long tail of tools and things to synchronize here. And it does make sense to have these different packages to synchronize different tools, maintain and manage by an open source can away. Not necessarily surprisingly, but 5GEN does a good job at doing that not from an open source standpoint, but just managing these packages. On the open source side of the house, there's airbites saying you're a Milano stitch. All these things work well. One thing is for different, for different data sync packages, why if you want to synchronize your HubSpot or for different packages, you might have different level of quality, where 5GEN might have pretty even predictable quality across the board and in the long tail of tools. Something like airbite, I think they do a good job at saying which one of their connectors at which level of maturity, right? So that's something to look into. That's an area where I would definitely give airbite Milano a spin before and so getting into a deep contract on the commercial vendor, depending on your needs, right, depending on how many systems you're trying to synchronize and what level of detail you need for these. So that's an area where open source is extremely competitive and definitely worth looking into. Here on a slide, I put segment and rudderstack that align more directly. These guys are a little bit more, they're slightly different. They're less your typical data sync type system and a little bit more of transport layer, often for customer data specifically. So that's an area where if you're looking into segment, you should definitely take a look at rudderstack to very well supported on a vendor as well. And then on to do it yourself, side of the house. Of course, you can do some of these things in Airflow and Daxter and Prefect, but would really recommend using a tool, using a product here that's managed for you. That makes a lot of sense. Okay, going to the next layer of the stack here, going into data catalog. So here we're getting in an area that's like, I think becomes more important as your data team grows and the number of data assets that you're trying to manage grow. So it might not be, in some ways it is a big company problem, not that it's not a nice to have for smaller data teams, but I would say that the need for a handle on your metadata and this kind of tooling grows exponentially as your data team grows. So here we've seen a very competitive market on the vendor side. Like we have a market that's like more or less validated or validating, right? So let it gigantic Tam market, and not everyone is shopping around for a data catalog, but it's been extremely competitive between the Elation, Atlin, Calibra. I'm certain there's other vendors in the space. On the open source side of the house, we have I think DataHub emerging as a really strong contender and solution here, backed by a company, a commercial open source company called Acril. And there's also a Munsen that's out of lift. I was around lift one this got created. So I have a little bit of bias there, but it's nice to have some diversity on the open source. Side of the house. All right, and that's as much as I'm gonna say about data catalog, but definitely worth looking into the solutions here. If I was looking at things, I would probably as a pro open source person, I would probably start with DataHub and compare that with vendors if I was in the market to buy or to add this layer to my stack. At fairly small data team type, or fairly small organization with data needs and we've been able to get by without having a full fledged solution in this area. All right, so data transformation or orchestration. So here I could have decoupled the two. I'd like to think of them as things that are decoupled in my head, but I think there's also a lot of good stuff that comes when you do couple these things. Talking in the abstract a little bit about data transformation, I think something that we've seen over the past five years or so is that SQL is becoming very much the main way by which people do data transformation. So I mentioned ELT before that T is really often primarily templated SQL. And for a lot of good reasons, right? So SQL is a language that people know very well. SQL is kind of convenient and easy and accessible to many people. So we've really seen like, I think the domination of SQL in the transform layer for better or for worse. And here I wanted to talk about this block pose that's pretty great and maybe resonated with me as the creator of Airflow more, but I think it's a really interesting pose that came out maybe a year or so ago. It's about essentially how our Airflow has been unbundled so the orchestrator that was used to do all sorts of things in the past and these mixed workload became kind of unbundled, right? Where the transform layer, if you do transformation in SQL, that's very much like the DBT type space, data sync that we used to write as Airflow task, manually maybe as Python script within Airflow DAGs. Now we have some of the vendors I mentioned earlier, similarly some of the ML workloads or metric centric things or what we now call a reverse ETL that used to be all done with custom scripts. And now we have great products to do this anyhow. So trying to list out a little bit some of the things you should look into when thinking about data transformation and orchestration. So first thing I wanna say is, I think this is a space where the vendors, if you wanna do transformation data, orchestration transformation as code, that's an area where the commercial entities have not done so well, right? So I was looking for logos to put on the right side of the house and really that's a space where dynamic is open source is much more dynamic and interesting to look at. So that's good news for all of us open source enthusiasts. Here for the SQL first type transformation, I would say like DBT is coming as a very dominant solution. So if you want a schedule, a lot of templated SQL, DBT is a really great solution to do that. It's not an orchestrator, right? DBT is not gonna allow you to run all sorts of Python scripts and to orchestrate with your spark jobs and other things. So airflow becomes a really good way to orchestrate things like DBT and other things and very commonly use across the board. I wanted to point out to that SQL mesh is kind of up in comma here. It's similar to DBT in some ways or in the same space but is perhaps more SQL aware, that understands the SQL that you're writing and therefore has a little bit more of a handle on the lineage and the actual data flow of what's happening behind the scene, where DBT might know which model, which dataset which model depends on which model, SQL mesh knows about say things like column lineage and such. So an interesting project to look into. On the orchestration first, there's probably other tools that are airflow. I don't, some people use some ARGO, which originally was a little bit more of a CICD tool but can be used for data pipeline as well. There's a great commercial open source solution here if you want to manage it. Airflow, there's astronomer. And then on the data flow, so this category of called them the data aware workflow engine or data flow slash workflow, that's been an area that's been growing quite a bit over the past five years. So, so dagster being super great. There's pre-fec, believe it's flight too, that was born, I lived around my time but I think those are interesting because their workflow engines, similar to air flow and some capacity but they are much more data aware and prescriptive as to how to do data flow. So they have a little bit more visibility inside the different workflow. I'm looking at the clock here. I'm gonna go a little bit faster to kind of make sure I can cover everything. So it's like a little bit of BI and dashboarding and this is an area where there's definitely a BIOS alert. So I am, you know, I've been dedicating pretty much the past like five years of my life or more on Apache SuperSet. So there's clear BIOS here by SuperSet and objectively I think is, you know, the project would probably the most traction in this space. I think you should definitely look into Metabase as well. I think Apache SuperSet is compelling because of the, you know, the governance model, the Apache Software Foundation provides a lot of guarantees and a very permissive license in Apache 2. I believe Metabase is AGPL. So that's one of these copy left licenses which may or may not be, you know, a problem depending on your needs. So here pointing out to preset, my company that, you know, commercializes or offers a managed service around Apache SuperSet here on the vendor side has been extremely dynamic with things like Tableau Power BI, Looker, you know, Mo, there's been acquisition in the space, very, very dynamic space. There's a lot of innovation. And that's, you know, I believe there are people who make a living of comparing the I tools. So here I'm not gonna go too deep and try to, you know, nod you into taking a look at Apache SuperSet that's really, really competitive in the space against even the leading vendors. So go open source. I believe the last section I have, and I'm trying to save time for some Q&A here, is the data of workspace and notebooks area. These like, REPL interactive coding environment are extremely powerful and that can be a really good model to do analytics, data science, data transformation. Personally, I love firing up just a Jupyter notebook and working from a notebook, especially when working with larger datasets and data frames. So extremely powerful. I'll talk about the commercial side. I think Hex has created a really interesting product in the space, the fact that it's a hosted notebook as opposed to say Jupyter, that's running on your laptop or on a VM somewhere, adds a social dimension, collaboration dimension, which is really awesome and powerful. Talking about things like, there's a lot of notebooks, it's very dynamic ecosystem. Google's got Google Collabs, a lot of the tools that are built here are built on top of Jupyter, or at least like respecting or trying to follow the Jupyter standard. Things like Databricks SageMaker, Azure notebooks sometimes are portal to underlying infrastructure. So say in the context of Databricks, you're in the Databricks notebook, but you can fire up these SparkJob and take advantage of the entire Databricks ecosystem and data platform. So in some ways these notebooks on the commercial side are a gateway to infrastructure and tooling and frameworks. So that's powerful. What I wanted to say on the open source side is you can get a lot of mileage out of just a hosted notebook, right? It's pretty easy to fire up a VM on EC2 instance and fire up a Jupyter kernel and work from that. So it's nice to have a hosted notebook solution, but it's also pretty easy to get by with just using Jupyter, Jupyter Hub, things like NB Viewer, if you wanna publish your new books as static assets, so there's a lot you can do with a very, very rich ecosystem. And as I approach the timer, kind of clock limit here, I'm gonna wrap up. So some parting words about all of this. So stacks are extremely complicated, right? I covered probably just a, you know, a tenth of the data stack. There is a lot to know. And how do you know how you make selections around a stack is pretty critical because when you pick something, it's pretty sticky and it's hard to migrate, right? Once you pick a database, once you pick a workflow engine, and it's a lot of work to move from one to the other. So it's really worth the time to make educated decisions on your stack. A good way to do it is to be on listening to talk like this one, is to talk with practitioners, talk to people at places like OSACON, ask them what they love, what they don't like about their current stack, and that can inform your decisions here because those decisions are important. Luckily, it's a lot easier than it used to be to pick things of your stack into. It's all in run it with all the hosted solutions. So that makes things a little bit easier to get started. And also like note that it's a fair amount of work to glue these things together. So if you pick whatever it may be, if you pick a air bite, you know, Starburst, Galaxy, preset, handful of other things, they're still a fair amount of work and getting these things to work together. So these hosted services are pretty convenient. So at least you don't have to be on call and run these things and keep them up day and night. So that's it. And then just happy to see how open source is dynamic and really strong contender in all of these layers of the stack and beyond. So that's all I got folks, and I've got maybe half a minute for questions. I'm gonna go and be at one, I said I've wanted to table, maybe the visualization table and the lounge if people wanna come and talk to me. I'll be there to take questions. So thank you.